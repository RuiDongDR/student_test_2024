{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b74ae1-ebe3-49d4-8fcb-e7885d5c4aa7",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "[Script of Scripts (SoS)](https://vatlab.github.io/sos-docs/index.html#content) is a scripting language designed for the execution of workflows that involve the analysis of data in multiple languages.\n",
    "\n",
    "\n",
    "It is a web-based notebook environment that allows the use of multiple scripting language in a single notebook, with data flowing freely within and across languages. SoS Notebook enables researchers to perform sophisticated bioinformatic analysis using the most suitable tools for different parts of the workflow, without the limitations of a particular language or complications of cross-language communications. If you are interested in `SoS`, you can read more about it in [this paper](https://academic.oup.com/bioinformatics/article/34/21/3768/5001386).\n",
    "\n",
    "In this notebook, you will explore some basic functions of `sos` in the analysis of UK Biobank, based on a simulated dataset. Before you start, first make sure that the general kernel for this notebook is in SoS (on the top right corner, you can select the SoS kernel after installation), and in each cell, you should choose the correct kernel (in the scroll-down list you should see at least three options `Python`, `R`, `SoS`).\n",
    "\n",
    "Please follow the instructions throughout this notebook and run all the cells. Add cells under each question (in `Python`, `SoS` or `markdown`) to answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6dbb05-9d59-4fe2-ab1d-a0cf6e55e6fd",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Intro -- set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d04086-3310-41f1-a2eb-f8c7e46ed2e9",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# set the kernel of this cell as SoS\n",
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803fc49f-c5d2-4816-b8ca-94b15b047d61",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the kernel of this cell as Python3\n",
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d490d-d073-468d-b887-2a6bea14dc01",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "You see they give you the same result. So you can write in python directly in a sos cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9ba1a-2af3-44d1-a6ad-ef8b2cae7318",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "# Download the toy data and preview\n",
    "\n",
    "Before we start any analysis, let's import the packages required first.\n",
    "\n",
    "Then please download the data under `data/toy_data.tsv` and import it in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14e46d-a23b-4493-9e3b-7e53665fc8e6",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import seaborn as sns # pretty plotting, similar to ggplot2\n",
    "import matplotlib.pyplot as plt # base plots\n",
    "\n",
    "import statsmodels.api as sm # similar to glm() in R\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c481dd0-531b-4220-bd4c-24f006048b46",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "If you have something reporting `No module named 'xxxx'` or `cannot import name 'xxxx'` that means it is not installed. Please refer to [this page](https://mamba.readthedocs.io/en/latest/user_guide/micromamba.html) to install the modules required under `micromamba` (you may need to restart the whole notebook process if necessary). Otherwise you can install them using `conda`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2992ea07-867b-49cc-ae60-b5479061ebe3",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "Then we import the data using `pandas` (note that you may need to change the path to where you store the downloaded data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f48fbf-568c-44c8-91c5-1bd7a3076714",
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "toy_data = pd.read_table(\"../data/toy_data.tsv\", low_memory=False)\n",
    "toy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17c913-81ed-4812-a9a5-0322b0f29d0d",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "You can also view it in SoS using the [Magic `%preview`](https://vatlab.github.io/sos-docs/doc/user_guide/magic_preview.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168710e8-f9ed-4a3d-845c-31b90b9ec2ee",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the kernel of this cell as SoS\n",
    "%preview -n \"../data/toy_data.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027bb8fd-d451-41ff-8db9-ec1d4085d278",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "# Exercise 1 - Explore the \"first occurence\" phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a7b3a-9ad7-410d-aec2-6c7a947b4f85",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "As you can see, the raw data are not very easy to understand!\n",
    "\n",
    "The first thing you want to understand is the column names, which we can do by searching in the UK Biobank [Showcase](https://biobank.ndph.ox.ac.uk/showcase/index.cgi). For example, search `31` and then you will see it actually represents [sex](https://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=31). Please read more into the data-coding of it (and other columns) and answer the following questions.\n",
    "\n",
    "Please finish this section all in `Python3` or `markdown` cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd745f9-58d8-4533-ac07-54c4a70872e9",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***\n",
    "**Question 1: how many females and males are in the toy data? What's the average age of all females now (as up to Jan-01-2024)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424effe8-733e-4fe7-b9b9-0a7ced865a17",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed655c00-a34a-48ab-bb35-6f0d53e9d572",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba8720-eb79-455a-ad2c-85421359a109",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Now you should know what the column names are. Then let's take a look at the phenotype columns. The easiest place to start is with the UK Biobank's pre-processed \"[first occurence](https://biobank.ndph.ox.ac.uk/showcase/refer.cgi?id=593)\" disease phenotypes. These phenotypes have been generated from all the sources listed above, and are encoded by 3-character [ICD-10 codes](https://icd.who.int/browse10/2019/en), which are a widely used international standard for cataloguing human diseases. Each disease (specified by an ICD-10 code) is encoded in two fields: one with the data source where the first occurence was observed (encoding described [here](https://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=2171)), and another with the date when that event happened.\n",
    "\n",
    "For example, if you search for \"transient ischaemic attack\" reveals that field 131056 contains the date of the first reported diagnosis and 131057 contains the source where the diagnosis was reported. Let's first rename the columns containing the first reported occurrence source and date for transient ischaemic attack (TIA) and stroke into human readable names and use those to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd108a31-6a60-4a07-a91c-29e42014e3b1",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "toy_data = toy_data.rename(columns={\n",
    "    'f.131057.0.0': 'TIA_first_occurrence',\n",
    "    'f.131369.0.0': 'stroke_first_occurrence'\n",
    "})\n",
    "\n",
    "# Checking what variable TIA_first_occurrence contains\n",
    "#   the variable includes codes for the diagnosis source and is missing (NA) for sampled without diagosis\n",
    "#   (40=Hospital admissions data only, 50=Self-report only, 51=Self-report and other source(s))\n",
    "toy_data['TIA_first_occurrence'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd85ef9-34ee-4d9d-88f9-6c923f5bb838",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Let's now count many cases of TIA and stroke are there and make a bar plot. First, this code counts the number of TIA and stroke cases (i.e. individuals with non-missing data in first occurrences for TIA and stroke). Then it reformats these numbers into a \"long\" format suitable for plotting using the function pivot_longer (which is explained in the comments of the code). Finally, it plots this data as a bar graph using the plotting function â€œggplot\" from the package ggplot2 (again, look at the comments to see how this plotti). Next, we want to calculate how many TIA and stroke cases are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ea3e7-89be-4a0e-8a34-3afce0738246",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the number of participants with a non-missing value for the first occurrence\n",
    "tmp = {\n",
    "    'TIA': toy_data['TIA_first_occurrence'].notna().sum(),\n",
    "    'stroke': toy_data['stroke_first_occurrence'].notna().sum()\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "tmp = pd.DataFrame(list(tmp.items()), columns=['phenotype', 'number_of_participants'])\n",
    "\n",
    "# tmp = pd.DataFrame(list(tmp.items()), columns=['phenotype', 'number_of_participants']).set_index('phenotype')\n",
    "\n",
    "# Define the colors for the bars\n",
    "colors = [\"#56B4E9\", \"#E69F00\"]\n",
    "\n",
    "# Plot the totals using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(data=tmp, x='phenotype', y='number_of_participants', hue='phenotype', legend=True, dodge=False, palette=colors, saturation=1)\n",
    "sns.despine()\n",
    "\n",
    "for x in range(0,2):\n",
    "    ax.bar_label(ax.containers[x])\n",
    "\n",
    "plt.title('UK Biobank processed data')\n",
    "plt.xlabel('Phenotype')\n",
    "plt.ylabel('Number of Participants')\n",
    "plt.legend(title='Phenotype')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e8f7c0-5aa4-4e2f-8c2c-36d9c7740f13",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "As we noted above, TIA and stroke are related, but distinct, vascular diseases. It is generally accepted to be extremely rare for a person to have both of these diseases. Let's see what we find in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3e4ad-de89-429b-a261-b0e3fa401983",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the three combinations: only TIA, both TIA & stroke, and only stroke\n",
    "tmp = {\n",
    "    'TIA_only': ((toy_data['TIA_first_occurrence'].notna()) & (toy_data['stroke_first_occurrence'].isna())).sum(),\n",
    "    'stroke_only': ((toy_data['stroke_first_occurrence'].notna()) & (toy_data['TIA_first_occurrence'].isna())).sum(),\n",
    "    'TIA_and_stroke': (toy_data['TIA_first_occurrence'].notna() & toy_data['stroke_first_occurrence'].notna()).sum()\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "tmp = pd.DataFrame(list(tmp.items()), columns=['phenotype', 'number_of_participants'])\n",
    "\n",
    "# Set the order for plotting\n",
    "tmp['phenotype'] = pd.Categorical(tmp['phenotype'], categories=['TIA_only', 'TIA_and_stroke', 'stroke_only'], ordered=True)\n",
    "\n",
    "# Define the colors for the bars\n",
    "colors= [\"#56B4E9\",\"#009E73\",\"#E69F00\"]\n",
    "\n",
    "# Plot the totals using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(data=tmp, x='phenotype', y='number_of_participants', hue='phenotype', legend=True, dodge=False, palette=colors, saturation=1)\n",
    "sns.despine() \n",
    "\n",
    "for x in range(0,3):\n",
    "    ax.bar_label(ax.containers[x])\n",
    "\n",
    "plt.title('UK Biobank processed data')\n",
    "plt.xlabel('Phenotype')\n",
    "plt.ylabel('Number of Participants')\n",
    "# plt.legend(title='Phenotype')\n",
    "ax.legend(title='Phenotype')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77432b15-ba45-45c2-ae70-96173f1dba56",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "Now let's take a look at the dates when these diagnoses were recorded in the UK Biobank data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ca5ca-ccc2-48b5-93b0-a1a3a8d540ce",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'f.131056.0.0' in toy_data.columns and 'f.131368.0.0' in toy_data.columns:  # Check if the columns exist to prevent errors on rerun\n",
    "    toy_data.rename(columns={\n",
    "        'f.131056.0.0': 'TIA_date_first_occurrence',\n",
    "        'f.131368.0.0': 'stroke_date_first_occurrence'\n",
    "    }, inplace=True)\n",
    "    print(\"Columns renamed!\")\n",
    "else:\n",
    "    print(\"Columns have already been renamed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c2ad0-db2d-4578-8d8e-ded7217083ac",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract years from dates\n",
    "toy_data['TIA_year_first_occurrence'] = pd.to_datetime(toy_data['TIA_date_first_occurrence']).dt.year\n",
    "toy_data['stroke_year_first_occurrence'] = pd.to_datetime(toy_data['stroke_date_first_occurrence']).dt.year\n",
    "\n",
    "# Plot a histogram of TIA year of first occurrence from individuals for whom it's not missing\n",
    "sns.histplot(toy_data['TIA_year_first_occurrence'].dropna(), kde=False, bins=range(int(toy_data['TIA_year_first_occurrence'].min()), int(toy_data['TIA_year_first_occurrence'].max()) + 2),\n",
    "            color='#56B4E9', linewidth=0)\n",
    "plt.title('Year TIA first occurrence')\n",
    "plt.xlabel('Year TIA first occurrence')\n",
    "plt.ylabel('Number of Individuals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e9613-241e-43f5-85be-0589eda2c009",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "***\n",
    "**Question 2: please draw the same plot for stroke.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b0cbc-3f82-412b-b3c8-e59a9a54f87c",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2640a3c3-104a-4ed9-ad5e-b4132c075685",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***\n",
    "**Question 3: make a bar chart of the number of TIA cases that occured before and after 2000.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d7167-6382-4e7e-ba40-fc89be8e05b3",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0127005b-825a-4440-9c62-ccf224bccfd5",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5185947-a725-4cd9-ac15-d4deb1755486",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "We save the renamed dataframe for next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9531336-cbf8-4ed3-934e-6dfbe64c8740",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "toy_data.to_csv('../data/toy_data_renamed.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357dbf5-d946-4b25-a5bf-bbda69b0a7bc",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Exercise 2 - Use genetic data to validate the diagnoses by the different clinical datasets\n",
    "\n",
    "Now let's see how strongly associated our different disease definitions are associated with genetic variants known to affect risk of these diseases. \n",
    "\n",
    "For stroke and TIA, a lot of genetic variants have been confidently associated with disease susceptibility (see https://www.ibdgenetics.org). So we have pre-calculated a genetic risk score (PRS). To understand PRS better, you can read more in [Sun et al. 2021](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1003498).\n",
    "\n",
    "The premise is that the participants diagnosed with TIA or stroke should have a higher genetic risk score than the average population, and thus changes in the distribution of scores between the different categories might help us infer whether it is appropiate to use one source of clinical data or both.\n",
    "\n",
    "We will start by loading the genetic scores from a file. And note that in this section we will all use `sos` cells. When you answer questions in this section, please also set the kernel of your answer to `SoS` instead of `Python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04cf7c-badc-44cb-a7a0-008faad556eb",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import seaborn as sns # pretty plotting, similar to ggplot2\n",
    "import matplotlib.pyplot as plt # base plots\n",
    "\n",
    "import statsmodels.api as sm # similar to glm() in R\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "PRS = pd.read_table(\"../data/toy_data_PRS.tsv\", low_memory=False)\n",
    "PRS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bfa5c-8149-4a72-bf50-9492e875c73d",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "Now we can look at the mean of the genetic score distribution for each phenotype. To do this we need to import the `toy_data` again into the `SoS` kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ddcdd8-3f0f-4a1e-9383-5a4df6da2840",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "toy_data = pd.read_table(\"../data/toy_data_renamed.tsv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9812a65e-143e-405d-bfd3-69f2e2252bef",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***\n",
    "**Question 4: Can you transfer the `toy_data` from Python3 into `SoS` kernel directly, without loading it again? Hint: check [Magic %get](https://vatlab.github.io/sos-docs/doc/user_guide/multi_kernel_notebook.html).** (Please just write down the code below and don't run it to avoid unnecessary conflict.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f50087-2f28-47de-9f7c-d27cc0909174",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666cbbd0-922d-432c-a913-51b4cde6aab5",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c8f3a0-9da8-45af-b476-9162593acbff",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "What we want to do now is to evaluate whether the distribution of the genetic score varies per category, and how it compares with the population control group. For this we will compute mean genetic score and its 95% confidence interval for each diagnosis category. First let's combine the PRS data with the diagnosis categories we created before and define the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df402ce-c6a2-47a7-b4a7-7db1ffddea07",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_PRS = pd.merge(PRS, toy_data, on='ID', how='left')\n",
    "# define diagnosis category\n",
    "df_PRS['TIA_first_occurrence_category'] = df_PRS['TIA_first_occurrence'].map({\n",
    "    20: 'Death register only',\n",
    "    21: 'Death register and other source(s)',\n",
    "    30: 'Primary care only',\n",
    "    31: 'Primary care and other source(s)',\n",
    "    40: 'Hospital admissions data only',\n",
    "    41: 'Hospital admissions data and other source(s)',\n",
    "    50: 'Self-report only',\n",
    "    51: 'Self-report and other source(s)'\n",
    "}).fillna('control')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198b5c3-c01b-423e-b4a9-29d8e2ac1ddb",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "Then let's calculate the mean value and 95%CI for the PRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16470d39-dab8-4b15-9505-a60ff57007fe",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TIA\n",
    "grouped_TIA = df_PRS.groupby('TIA_first_occurrence_category')\n",
    "df_PRS_means_TIA = grouped_TIA.agg(\n",
    "    N=('TIA_PRS', 'size'),\n",
    "    PRS_mean=('TIA_PRS', 'mean'),\n",
    "    PRS_std=('TIA_PRS', 'std')\n",
    ")\n",
    "df_PRS_means_TIA['ci_low'] = df_PRS_means_TIA['PRS_mean'] - t.ppf(1 - 0.05 / 2, df_PRS_means_TIA['N'] - 1) * df_PRS_means_TIA['PRS_std'] / (df_PRS_means_TIA['N']**0.5)\n",
    "df_PRS_means_TIA['ci_upper'] = df_PRS_means_TIA['PRS_mean'] + t.ppf(1 - 0.05 / 2, df_PRS_means_TIA['N'] - 1) * df_PRS_means_TIA['PRS_std'] / (df_PRS_means_TIA['N']**0.5)\n",
    "df_PRS_means_TIA.reset_index(inplace=True)\n",
    "df_PRS_means_TIA.rename(columns={'TIA_first_occurrence_category': 'category'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de09c78-c52f-4405-8fcf-63c029b99584",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = df_PRS_means_TIA\n",
    "sns.pointplot(data=data, x='category', y='PRS_mean', color='blue', linestyle='none', errorbar=None)\n",
    "plt.errorbar(data['category'], data['PRS_mean'], yerr=[data['PRS_mean'] - data['ci_low'], data['ci_upper'] - data['PRS_mean']], fmt='none', color='blue', capsize=5)\n",
    "\n",
    "\n",
    "# Annotate with the number of participants\n",
    "for i, row in data.iterrows():\n",
    "    plt.text(row['category'], row['PRS_mean'] + 0.0005, str(row['N']), ha='center', va='bottom')\n",
    "\n",
    "# Set the title for the subplot\n",
    "plt.title('TIA')\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Turn off grid\n",
    "plt.grid(False)\n",
    "\n",
    "# Set background to blank and draw axis lines\n",
    "plt.gca().set_facecolor('white')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5882fd1-70ab-4b83-b496-b7d382f0dd03",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***\n",
    "**Question 5: please draw the same plot for stroke. Note that please name the variables in the same way as we do to TIA, so your output would include a variable named `df_PRS_means_stroke`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f177e1-cd92-4a24-840e-c9d4451d35d9",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f84c9db-1f1b-4491-9471-6e46099b47f1",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bfe512-1c06-48ab-b552-3022b1478f71",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "**Question 6: is there any shared pattern between TIA and stroke categories, and why is that? For each trait, which is the category with highest mean polygenic risk scores, and the one with the lowest?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eeb306-412b-4a48-bae3-a907238df455",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a7abd-0013-464a-8b9e-95b706b375b3",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76f91b9-95fb-46e7-bf77-5f480598c0d3",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Python3",
     "python3",
     "Python3",
     "#FFD91A",
     {
      "name": "ipython",
      "version": 3
     }
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
